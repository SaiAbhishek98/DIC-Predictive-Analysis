{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Predicitve_Analytics.py\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# import seaborn as sn\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscorenormalisation(X_train):\n",
    "    sta_vec = np.std(X_train ,axis = 0)\n",
    "    mean_vec = np.mean(X_train, axis = 0)\n",
    "    \n",
    "    for row in range(X_train.shape[0]):\n",
    "        for col in range(X_train.shape[1]):\n",
    "            X_train[row][col] = (X_train[row][col] - mean_vec[col])/sta_vec[col]\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "df = import_data('data.csv')\n",
    "\n",
    "input_data = df.values\n",
    "\n",
    "X = input_data[:, :input_data.shape[1]-1]\n",
    "y = input_data[:, input_data.shape[1]-1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "X_train = zscorenormalisation(X_train)\n",
    "X_test = zscorenormalisation(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center(cluster_centers, row, k):\n",
    "    \n",
    "    rows = np.tile(row, (k,1))\n",
    "    \n",
    "#     diff_vector = np.sum(np.absolute(cluster_centers - rows), axis = 1)\n",
    "    diff_vector = np.sqrt(np.sum(np.square(cluster_centers - rows), axis = 1))\n",
    "    \n",
    "    return np.argmin(diff_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \n",
    "    \"\"\"\n",
    "    diff = y_true - y_pred\n",
    "    t = np.where(diff == 0)\n",
    "    return t[0].shape[0]/y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    labels = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "    macro = []\n",
    "    tp = [0 for x in labels]\n",
    "    fn = [0 for x in labels]\n",
    "    for i in range(len(labels)):\n",
    "        for x in range(y_true.shape[0]):\n",
    "            if y_true[x] == labels[i]:\n",
    "                if y_pred[x] == y_true[x]:\n",
    "                    tp[i] = tp[i] + 1\n",
    "                else:\n",
    "                    fn[i] = fn[i] + 1\n",
    "        \n",
    "\n",
    "    \n",
    "    return np.sum(tp)/(np.sum(tp)+np.sum(fn))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    labels = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "    macro = []\n",
    "    tp = [0 for x in labels]\n",
    "    fp = [0 for x in labels]\n",
    "    for i in range(len(labels)):\n",
    "        actual = y_true\n",
    "        pred = y_pred\n",
    "        \n",
    "        act_diff = actual - labels[i]\n",
    "        pred_diff = pred - labels[i]\n",
    "        \n",
    "        for x in range(y_true.shape[0]):\n",
    "            if y_pred[x] == labels[i]:\n",
    "                if y_pred[x] == y_true[x]:\n",
    "                    tp[i] = tp[i] + 1\n",
    "                else:\n",
    "                    fp[i] = fp[i] + 1\n",
    "    \n",
    "    return np.sum(tp)/(np.sum(tp)+np.sum(fp))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WCSS(Clusters):\n",
    "    \"\"\"\n",
    "    :Clusters List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    wcss = 0\n",
    "    # Get a cluster\n",
    "    for cluster in Clusters:\n",
    "        \n",
    "        cluster_center = np.mean(cluster, axis = 0)\n",
    "        \n",
    "        # Compute all distances from cluster center.\n",
    "        center_vector = np.tile(cluster_center, (cluster.shape[0], 1))\n",
    "        \n",
    "        \n",
    "        wcss = wcss + np.sum(np.sqrt(np.sum(np.square(center_vector - cluster), axis = 1)))\n",
    "#         wcss = wcss + np.sum(np.absolute(center_vector - cluster))\n",
    "    \n",
    "    return wcss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    :type y_true: numpy.ndarray\n",
    "    :type y_pred: numpy.ndarray\n",
    "    :rtype: float\n",
    "    \"\"\"  \n",
    "    cf_matrix = np.zeros((11,11))\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    \n",
    "    for x in range(y_true.shape[0]):\n",
    "        cf_matrix[y_true[x]-1][y_pred[x]-1] = cf_matrix[y_true[x]-1][y_pred[x]-1] + 1\n",
    "    \n",
    "    return cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,X_test,Y_train):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    k=10\n",
    "    labels = np.zeros(X_test.shape[0])\n",
    "    for x in range(X_test.shape[0]):\n",
    "        row = np.tile(X_test[x], (X_train.shape[0],1))\n",
    "        diff_matrix = np.sum(np.absolute(X_train - row), axis=1)\n",
    "        labelled_matrix = np.vstack((diff_matrix, Y_train))\n",
    "        labelled_matrix = labelled_matrix.T\n",
    "        sorted_matrix = labelled_matrix[labelled_matrix[:,0].argsort()]\n",
    "        top_k = sorted_matrix[:k]\n",
    "        labels[x] = stats.mode(top_k[:,1])[0]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X_train,Y_train,X_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    Covariance = np.dot(X_train.T, X_train) / (N-1)\n",
    "    __ , vector = np.linalg.eig(Covariance)\n",
    "    return np.dot(X_train, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X_train,N):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type N: int\n",
    "    :rtype: List[numpy.ndarray]\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_centers = X_train[np.random.choice(X_train.shape[0], size = N), ]\n",
    "    clusters = [np.zeros((1,X_train.shape[1])) for x in range(N)]\n",
    "    \n",
    "    epochs = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        clusters = [np.zeros((1,X_train.shape[1])) for x in range(N)]\n",
    "        \n",
    "        print('starting main loop')\n",
    "        for x in range(X_train.shape[0]):\n",
    "            center_index = find_center(cluster_centers, X_train[x], N)\n",
    "\n",
    "            # Adding the new point to the cluster.        \n",
    "            clusters[center_index] = np.vstack((clusters[center_index], X_train[x]))\n",
    "        \n",
    "        print('recomputing center.')\n",
    "        \n",
    "        # Recomputing the center.\n",
    "        for x in range(cluster_centers.shape[0]): \n",
    "            cluster_centers[x] = np.mean(clusters[x], axis = 0)\n",
    "        \n",
    "        print('done computing centers.')\n",
    "\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SklearnSupervisedLearning(X_train,Y_train,X_test, Y_test):\n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "#     # Scaling\n",
    "# #     sc = sklearn.preprocessing.MinMaxScaler()\n",
    "# #     x_train = sc.fit_transform(X_train)\n",
    "# #     x_test = sc.transform(X_test)\n",
    "    \n",
    "#     # Training SVM\n",
    "    \n",
    "#     svc_clf=SVC(kernel ='linear', C=1, gamma=1)\n",
    "#     svc_clf.fit(X_train, Y_train)\n",
    "#     y_pred_svc= svc_clf.predict(X_test)\n",
    "#     print(\"SVM Accuracy: \" + str(accuracy_score(Y_test, y_pred_svc) * 100))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # confusion matrix - SVM\n",
    "#     cm_svc = confusion_matrix(Y_test, y_pred_svc) \n",
    "    \n",
    "    \n",
    "#     # Training KNN\n",
    "#     knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "#     knn_model.fit(X_train, Y_train)\n",
    "#     y_pred_knn = knn_model.predict(X_test)\n",
    "#     print(\"KNN Accuracy: \" + str(accuracy_score(Y_test, y_pred_knn) * 100))\n",
    "    \n",
    "    \n",
    "#     # Confusion Matrix - KNN\n",
    "#     cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "    \n",
    "    \n",
    "#     # Decision Tree\n",
    "#     dt = DecisionTreeClassifier(max_leaf_nodes=50, random_state=0)\n",
    "#     dt.fit(X_train, Y_train)\n",
    "#     y_pred_tree = dt.predict(X_test)\n",
    "#     print(\"Decision Tree Accuracy: \" + str(accuracy_score(Y_test, y_pred_tree) * 100))\n",
    "    \n",
    "#     # Confusion Matrix - DTree\n",
    "#     cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "    \n",
    "    # Logistic Regression Model\n",
    "    logclf = LogisticRegression(random_state = 0, penalty = 'l1', solver='saga', class_weight='balanced', multi_class='multinomial')\n",
    "    logclf.fit(X_train, Y_train)\n",
    "    y_pred_log = logclf.predict(X_test)\n",
    "    print(\"Logistic Regression Accuracy: \" + str(accuracy_score(Y_test, logclf) * 100))\n",
    "    \n",
    "#     results.append(y_pred_svc)\n",
    "#     results.append(y_pred_knn)\n",
    "#     results.append(y_pred_tree)\n",
    "    results.append(y_pred_log)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SklearnVotingClassifier(X_train,Y_train,X_test, Y_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    :type X_train: numpy.ndarray\n",
    "    :type X_test: numpy.ndarray\n",
    "    :type Y_train: numpy.ndarray\n",
    "    \n",
    "    :rtype: List[numpy.ndarray] \n",
    "    \"\"\"\n",
    "        \n",
    "    eclf1 = VotingClassifier(estimators=[('lr', logclf), ('dt', dt), ('knn', knn_model), ('svc', svc_clf)], voting='hard')\n",
    "    eclf1 = eclf1.fit(X_train, Y_train)\n",
    "    y_ens = logclf.predict(X_test)\n",
    "#     print(\"Ensemble Model Accuracy: \" + str(sklearn.metrics.accuracy_score(Y_test, y_ens) * 100))\n",
    "    return y_ens\n",
    "\n",
    "def GridSearchSVM(X_train, Y_train):\n",
    "\n",
    "    # Scaling\n",
    "    sc = sklearn.preprocessing.MinMaxScaler()\n",
    "    x_train = sc.fit_transform(X_train)\n",
    "    \n",
    "    \n",
    "    # Grid Search - SVM\n",
    "    parameters = {'kernel':['linear'], 'C':[0.00001, 0.0001,0.001,0.01,0.1, 0.5, 0.8]}\n",
    "    # parameters = {'kernel':['linear'], 'C':[0.1,10,20,40,70,100,200,260,512]}\n",
    "    clfGridSV = GridSearchCV(svc_clf,parameters,cv=3)\n",
    "    clfGridSV.fit(X_train,Y_train)\n",
    "    accuracy_SVM=clfGridSV.cv_results_['mean_test_score']\n",
    "    plt.ylabel('Accuracy Of Linear Kernel SVM')\n",
    "    plt.xlabel('Regularization Parameter (C)')\n",
    "    plt.plot([0.00001, 0.0001,0.001,0.01,0.1, 0.5, 0.8],accuracy_SVM)\n",
    "   \n",
    "    \n",
    "def GridSearchSVM(X_train, Y_train):\n",
    "    \n",
    "    # Scaling\n",
    "    sc = sklearn.preprocessing.MinMaxScaler()\n",
    "    x_train = sc.fit_transform(X_train)\n",
    "    \n",
    "    # Grid Search - DTree\n",
    "    parameters = {'max_depth': [3,6,9,12]}\n",
    "    gs_tree = GridSearchCV(estimator,parameters,cv=3)\n",
    "    gs_tree.fit(x_train,y_train)\n",
    "    accuracy_gs_tree=gs_tree.cv_results_['mean_test_score']\n",
    "    plt.ylabel('Accuracy Of Decision Tree')\n",
    "    plt.xlabel('Regularization Parameter (max_depth)')\n",
    "    plt.plot([3,6,9,12],accuracy_gs_tree)\n",
    "\n",
    "def GridSearchKNN(X_train, Y_train):\n",
    "    \n",
    "    # Grid Search - KNN\n",
    "    parameters = {'n_neighbors': [1,3,5,10,15,30]}\n",
    "    gs_knn = GridSearchCV(model,parameters,cv=5)\n",
    "    gs_knn.fit(x_train,y_train)\n",
    "    accuracy_gs_knn=gs_knn.cv_results_['mean_test_score']\n",
    "    plt.ylabel('Accuracy Of KNN')\n",
    "    plt.xlabel('Regularization Parameter (n_neighbor)')\n",
    "    plt.plot([1,3,5,10,15,30],accuracy_gs_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreate your own custom functions for Matplotlib visualization of hyperparameter search. \\nMake sure that plots are labeled and proper legends are used\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
    "Make sure that plots are labeled and proper legends are used\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "K_clusters = Kmeans(X_train, k)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(WCSS(K_clusters))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.76618601e+00  1.41063062e-01 -7.05023645e-02 ... -8.23321600e-06\n",
      "   1.33054387e-05 -5.49644651e-06]\n",
      " [-1.80230248e+00 -5.14345531e+00  1.04877802e+00 ...  2.51316160e-05\n",
      "   1.39384120e-05  3.35489134e-06]\n",
      " [-4.62899403e+00  5.70147241e-01 -2.06546064e-01 ... -6.34725045e-08\n",
      "  -1.09501304e-05 -7.36333563e-06]\n",
      " ...\n",
      " [-7.30578815e-01  1.60339097e+00 -3.50987211e+00 ... -3.02131617e-06\n",
      "   1.80793214e-07  1.06166782e-06]\n",
      " [-5.33428142e+00  9.49478082e-01  9.23443769e-01 ...  4.87389830e-06\n",
      "  -1.93034038e-05  4.81275218e-06]\n",
      " [ 2.30791616e+00  3.36582379e+00  2.47445477e+00 ... -1.90478036e-05\n",
      "   1.22871639e-05  2.64681671e-07]]\n",
      "--- 0.02955794334411621 seconds ---\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SklearnSupervisedLearning(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
